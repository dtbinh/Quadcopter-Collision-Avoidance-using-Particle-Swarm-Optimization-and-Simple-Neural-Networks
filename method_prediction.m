function [Y,Xf,Af] = method_prediction(X,~,~)
%MYNEURALNETWORKFUNCTION neural network simulation function.
%
% Generated by Neural Network Toolbox function genFunction, 02-Jul-2017 11:46:03.
%
% [Y] = myNeuralNetworkFunction(X,~,~) takes these arguments:
%
%   X = 1xTS cell, 1 inputs over TS timesteps
%   Each X{1,ts} = Qx3 matrix, input #1 at timestep ts.
%
% and returns:
%   Y = 1xTS cell of 1 outputs over TS timesteps.
%   Each Y{1,ts} = Qx1 matrix, output #1 at timestep ts.
%
% where Q is number of samples (or series) and TS is the number of timesteps.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1.xoffset = [0.273644685725802;1.72527095745334;1.72527095745334];
x1_step1.gain = [0.0136769088840276;0.150706470532015;0.150706470532015];
x1_step1.ymin = -1;

% Layer 1
b1 = [-4.0256923692465536;-3.5724995732714113;3.2453408239888435;-2.4901646528027706;2.4930214768576198;2.2361548194380263;1.2036408963136584;-1.301744026315806;-1.5830243045946768;-0.0034092910893547684;0.069180745524198214;0.19414123550964005;-1.2142275405857201;3.2494985603153066;-1.1179542404551754;-3.2518649562679829;-1.591262474907567;-3.6428396288832574;4.5796335190904545;-5.1767585465815191];
IW1_1 = [3.0669443449331015 1.743823843278363 0.63132444175312286;2.0478043696672263 -2.6502349249889168 1.4094107938836884;-3.6739669198067975 0.42701352185013447 -0.80392733612878409;1.8786007896876862 2.3690147371699029 2.4238902548766541;-1.5246593161760911 2.1887400384815772 2.2121892007752741;-1.8582025498683234 -2.8534308276492775 -0.18459043469654848;-2.5758847491865788 2.1689721083099687 2.6950935563576137;1.2452522412609428 -0.85822834480530685 -3.528068497053424;3.2519167062727417 0.47487790297770849 -0.0042695323348442039;3.0798165793506715 -1.7458160539095331 2.5136072017844757;-0.99866842411660783 -1.255402841313942 3.4249061191123462;1.5178243918477408 3.0696818356907443 -1.8483356707956127;-2.8559662893323341 1.9739743826875285 1.6217038771165955;4.0836891227405969 0.53850333134412021 -0.60528230243313896;-1.0045791672981987 -2.3050841640562356 3.2926087254403984;-0.13663243576092504 1.0250644620028786 3.1598137279097842;-1.2890784170199199 3.9328216228703941 -3.1942567598149876;-0.223184787250267 3.2893090692179494 2.3026545533444276;2.120838329683933 0.37104103755944645 1.8481789985763726;-0.75951449749013633 1.2506406534634387 -2.2006804232371837];

% Layer 2
b2 = 1.2324666584414503;
LW2_1 = [0.19226814571285733 0.33042876897567147 -0.6495793784799142 0.75855702679062154 -0.93534494215934261 -0.079976677705344751 -1.0422301830530971 -0.45022112164924927 -1.197870268569863 0.9098355724600925 0.23339047589242251 1.258869135792146 -0.97770123226610151 -2.0426224514782225 1.111430446819073 -0.9838400017740041 1.057244065073873 -1.5236528856687332 0.50571559428105728 -1.2270228351264407];

% ===== SIMULATION ========

% Format Input Arguments
isCellX = iscell(X);
if ~isCellX
    X = {X};
end

% Dimensions
TS = size(X,2); % timesteps
if ~isempty(X)
    Q = size(X{1},1); % samples/series
else
    Q = 0;
end

% Allocate Outputs
Y = cell(1,TS);

% Time loop
for ts=1:TS
    
    % Input 1
    X{1,ts} = X{1,ts}';
    Xp1 = mapminmax_apply(X{1,ts},x1_step1);
    
    % Layer 1
    a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*Xp1);
    
    % Layer 2
    a2 = logsig_apply(repmat(b2,1,Q) + LW2_1*a1);
    
    % Output 1
    Y{1,ts} = a2;
    Y{1,ts} = Y{1,ts}';
end

% Final Delay States
Xf = cell(1,0);
Af = cell(2,0);

% Format Output Arguments
if ~isCellX
    Y = cell2mat(Y);
end
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings)
y = bsxfun(@minus,x,settings.xoffset);
y = bsxfun(@times,y,settings.gain);
y = bsxfun(@plus,y,settings.ymin);
end

% Sigmoid Positive Transfer Function
function a = logsig_apply(n,~)
a = 1 ./ (1 + exp(-n));
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n,~)
a = 2 ./ (1 + exp(-2*n)) - 1;
end
